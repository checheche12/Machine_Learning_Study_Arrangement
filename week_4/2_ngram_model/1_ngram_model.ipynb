{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b546feb6",
   "metadata": {},
   "source": [
    "### N-gram model\n",
    "\n",
    "- 현재 단어를 볼 때, 직전의 N-1 개의 단어만 보고, 다음 단어의 확률을 계산 함\n",
    "- 문장을 확률로 다루는 가장 고전적인 방법이고, 이 때 까지는 단어를 벡터로 바꾸는 기술은 없었었다.\n",
    "  - Unigram (N=1): 이전 문맥 없이 단어 빈도만 봄\n",
    "  - Bigram (N=2): 직전 1개 단어만 봄\n",
    "  - Trigram (N=3): 직전 2개 단어만 봄\n",
    "- 구현이 매우 빠르고 간단하다.\n",
    "- 대신 정확도는 많이 떨어진다.\n",
    "\n",
    "\n",
    "### N-gram model 예시\n",
    " - 나는 오늘 학교에 간다 를 띄어쓰기 기준으로 보면,\n",
    " - [\"나는\", \"오늘\", \"학교에\", \"간다\"]\n",
    " - Unigram (N=1)\n",
    "   - P(\"간다\") = 단어 \"간다\"가 전체에서 등장한 비율\n",
    " - Bigram (N=2)\n",
    "   - P(\"학교에\" | \"오늘\")\n",
    "   - P(\"간다\" | \"학교에\")\n",
    " - Trigram (N=3)\n",
    "   - P(\"학교에\" | \"나는\", \"오늘\")\n",
    "   - P(\"간다\" | \"오늘\", \"학교에\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAABQCAYAAACdzyc1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABaGSURBVHhe7Z0JtFXTG8B3hoyZhfAUKSJDXqgoMmYtiWrJMyVjg5ApLSJzUchUKkOGzCI9FJlDeIlUMqSMmacMRee/f19nv//pdt9959xz7uvc+n5rnfXePffcM+797W/a36nlWYyiKIoSilX8v4qiKEoIVGgqiqJEQIWmoihKBFRoKoqiRECFpqIoSgRUaCqKokRAhaaiKEoEVGgqiqJEQIWmoihKBFRoKoqiRECFpqIoSgRUaCqKokRAhaaiKEoEVGgqiqJEQIWmoihKBFRoKoqiRECFpqIoSgRUaCqKokRAhWYR8sUXX5iBAweahQsX+mvSy3///We+//578+233y6z/Prrr/5WipIMf/zxhzn//POljxQKFZpFBo3htNNOM+3btze1a9f216aXd9991xx//PFmwoQJZsyYMaZVq1bmySeflM8dO3Y0FRUV/paKEp91113XdOnSxVx88cXmt99+89cmiwrNImLRokVm8ODBpmvXrmbHHXf016abmTNnmpEjR5oTTjjBNG7c2Oywww7muOOOk8/dunUzG220kb+loiTDHnvsYVq3bm369+8vfSZpVGgWEaNHjxazFi2zGPj999/NOuusY7baaiv5/OKLL5omTZrIOlhjjTVUaCoFoayszPzwww/mqaee8tckhwrNIuGzzz4zw4cPN3379jVrrbWWvzbd1KlTx3Tq1En+X7BggZkxY4bZf//95TNgnq+33nr+J0VJDvpIjx49zJAhQ8y8efP8tcmgQrMI+Pfff+Xh77nnnmbnnXf21xYXX375pQSEtttuO3+NohQW+kujRo3MrbfeajzP89fGR4VmETB9+nQJnOAHXG211fy1xcVHH31kNtlkk0pTXVEKDX2le/fuZty4ceJbTwoVmimHEfK+++4zO+20k2natKm/tnDgOEcrTJpXX31VrsH5MxWlJqDPEIC88847E9M2VWimHPwx5eXl5thjjy2YLxNBSSrTQw89JD7HK664wv8mPo8++qiM9vz98MMPzaWXXqr5mUqNQZ85/PDDzdNPP52Yb1OFZsp59tlnzeLFi03z5s39NcnzzTffmHvvvdesvvrqZtVVV/XXJgOBoNtvv93MmTNHhP+AAQPM+uuv73+rKIWH3OC//vrLvPDCC/6aeKjQTDFEnEkER2BuueWW/trkKSkpMf369TOHHHKIms/KCsc222wjfYhB+++///bX5o8KzRQzd+5c88EHH4jJXKwBIEVZ3qy55pqibU6bNk3ynOOiQjPFvPnmm6JtFsvsH0VJK7vttpv57rvvzJQpU/w1+aNCM6UQ6Xv77bclRSfNuY0EkWiMwUIccZckTChFCdKgQQNTt25d6VNxqWU7Z3JZn0pi/PLLL+aII46QoMmDDz5o1l57bf+bwoFW27lzZ7P11lvL7KMw4D7AF0p1mVq1asn/m2++uf9tdj7//HPzySefyP/8jmsNQkGS6667TvanKElAO2MGGjz22GNS2CNvEJpK+pg1a5ZXUlLi9ezZ019TeGzD8tq1a+dZoeWvqZ7Fixd7N9xwg1enTh1ZzjzzTG/hwoX+t+Fge2s2eaeeeqrso379+t6MGTP8bxUlPrTTbt26eQ0bNvTmzJnjr80PNc9Tytdffy0aWNqnHaINWmFXOaf87rvvNsOGDZP/w0KqE9HNO+64Q3xOZAo88cQT/reKEh/aKbGBH3/8UVLs4qBCM6WQ12gHNSmllnZIU7LaZqVZPmjQIKmjmQ9cL3U3mTqKr7QYeeedd2QAKDSk0Dg3x8oGEySuv/76SDUzqahFHQdqIMQhL5/mxIkTZT5nNug4FAHddttt5TMXR7GJn3/+WT4HIY2Gunf4wdxsl2z7JmWgV69ekk+4skCDYGbO2LFjl6oMVAhoRNS4/Pjjj6Wc1iqrrCLPsUWLFlLsIKw/lZzSE088UZLxmzVrZh5//PG8S79Nnjy5UgN10Dbuv/9+ERT4XJmWWSgIRnGMTz/91F+zNKWlpebII4+USk5BGCxuueUWWQqd8zpq1CipHUlkeGWEe02bu+SSS6StVMczzzxjjj76aJlgcc455/hr8wChGRV8X7Nnz/ZatWrlNWrUyHv//fc9q/LK8sADD3ibbbaZ169fP/FVWcnuWY3BGzFihPirrCCo3Ba/nb0Iz6rN3rRp05bZd4MGDTw7anvz58+P7CcrdvAr1q1b15s6daq/Jv0sWrTIO/vss2P5N3NB26Ad1cR9wQdmTTlpz1wLx3XtlvbesWNHzworb968ef4vlpyfVRhq7JmNHDkyNe3jq6++kqUQ/PTTT54dvPxP/4dndNVVV3lDhw711+TGCllpO3HjBHmZ54yg9erVk1qITLvbdNNNRTNhOeaYY8yFF15obr75ZhkF3PduRgu/ddsykR4tFH+D7Wyiagf3jYbJ70gVCDOSrCig5eB74fqLpXYmYDkwirds2VI+UzQZEzIpaBtoeBtvvLG/pnDQJtGS0b433HBDs++++1a2W4pAMIMKv/Ndd93l/2KJJsPzKtbyfXHAJUHyeCHAVZVtCiTPqEOHDmKNhSkygwUFcau5F8Sn6fxwL730kvzNBSk1THOyWqfMgFGWvIzszz//FCFRbPO0Gezs6C/njZnOYJhkWa6ahMHLapXSnjOnsZJPynxmB9uSGnbooYeudLO3rPJlXnnlFf9T8pBbabV4/9PS4AZkEGUiSHVssMEG0j4pTkN6Xb4URGhaE0b+hon80tjwozGa14QGEQVe10CxiT59+shoRifBkUyZM6qQW3PEvPfee/JAGQ3pSDyQ+fPnyzb85vnnnzfWvDCTJk0y1tSTvEYa2YoMfrbLLrtM/kdjxvIo1EuuHGiE+LZ4E+Fbb70lA08Qng33H18jfkqq3vCOotdff93fYlk4dwJSu+yyy1J5fTw/nicDA7m0wP6popM5e4ttaSNkA9CeHG57oB1hlcXVgKqCY/H20t69e0t7Dp4H9+m5556TNs42QY2NGqi0YWIMPD+uA187RWTcgEH/RdvmPVBvvPGGbI/WGcQ9Gxb2wT0hxkHfoL/wPFi433zmfOlPHJNzu/LKK+U5sG/6FX3QgTVGseEwChrbJmGxJi40uRmUGONCCArkwjU+bhBvj8MsjwsjCDc9zJKrRNnUqVNN27ZtpfIzD40H3LNnz8qGTeejgzzyyCPyENGo2J5r/+eff2ShgVHSjY6MplK/fn0JktFAc3UQGjUJ4MUMBZN5ARzQoEeMGFGQwYJ94griXuPcxz2AKXfBBRdU3mMCBu3atZNnQFCNc8OUZJYIFk5VzJ49WxQATHMHQoYyd0T4CZLtuuuusp7tOBdcUUGohYqgoD1xTmxDe7noooskywBI5Cehn9J5ScM7cvbbbz+Ze8294dxPP/10EXYIJd4UyrkjMGmbCFb3Xh3OE2HPayMY+BBqJIiTKcGgyLWgEGD2ZgbEwD0b+sYZZ5xhTjrpJElP4xyA/oc7b6+99hIZgMDmPE8++WR5ZvRl+gLuuVzQR3kdTBztMRL2wvICpzeJ0Ha09aywkP8PPvhgr3nz5t6NN97o2Qvwt1xCeXm5ONQJ+rAtS8uWLb1OnTp5FRUV/lZLcPtmWxzvUSC4ZB90qMWq9OJMzsSaxl6HDh08+6Arv8fhbk0Bb/LkyfKZAIftfF7nzp3lHHv16rVUUACGDBmyzDVYISv3zGoW/pplYXt+l8/1pwnuB8ESnjvXPH78eP+b/OE5cF9cAMQKSG/77bf3rMCRz0BAomnTpnKvreD0rPCWwI3VjuR7K6SknVoLRz5XBdtZc85r06ZNZZu1AtSzAm+Z50L75nvaroMAptWuPCscpD2dd955sp7za9KkiTdq1Cj5PHfuXNmvu6awVBcIslqbZ4W6tEOgzdoB3LNKgPxvhbicF+3dwTPi/tpBWz67fmuVAfkM3Jfgtbr2yrZBeCZM0Ag+d86ldevWnlWu5DMBnsaNG8u1WDO8MoDscLLAXUM2OG6YvuLOEzllhbG/NjqxnS9oh6SB4CAPAyNNnHA/IySvfrAXLup2JgSXWOJASgsmXsOGDc1ZZ50l6xjFGBndlD/UfDRQ0k4ocorZw/TD6iCNh3vFNSTxVslcKV1B8LOhYQTvDf6dKEQ1sbkfaGNcp+0IUoB49913N1tssYW/RXwIvnBtwdQmzGbm7DsfY9CcCwvtDD8Z6TyYhfjDooLLiRfhYTXgG8VSAXz37J+0LMAthUvDtR80ZMxQ2kqcQCCuIDQwF5iizTrtFq2Rt4PyPILHoD/zHdo67gvge7Q5R9iaq1iR9Be0bUx64NpJceP6AZ8kWi7aLOmHpHkVOuiLC8AK47ynUhbEp1lIEF4ItEKCCcaCQBw6dKgs5MThe7Wjnr/VEqFA/iimBUIhDDQ4zJlc5nkUEBCYXe48q1oQrJmDCUIwypIPdHxcL0Q6cVWEHVzDkuu8CKZxXJ4RAyGCCyFCB8YszeVDx32DCU+kPB+BCXR+clwRgBwLAQWYngh13DVAm8Z14AQ/ZjruDAJpccBPiMDLdp20PwRHVeRyXVVF0FcKHAPFBreEa4f4bokHBNsBAxtmudUEqxzgMvcdB4RlHMFcdEKThoATOpuWCfgYebd2mAVfYzZhhw+Fl4BlPihGRzdCAo0fnxj+GrQIRrDqoDHSScgYWJnAn8U9QoglCfcR4RIM/NBZ3T1GaOGbPPfcc2WwJWiB/xNBmgsGQmYkof2EhUE12D4cFRUVInydUEQDxIphwAt+BnyEBFIQovjFrTUo6/OB5H/OJzMdB2HJO+cRXAip4DHoW9zLfKw1AlqABcagwz7YlwsaOTi+e14cmyASliPgK82mULh9o7zgI84EX3JVMiET+nbYbbNRVEKTG9e/f/+cIz9VehjJwiw44GvXru3/8v9goiAImdHiIpw8XDoc2gqwfvDgwbIdIylaJ/vLfOA0WjowsA+itmiaaLFVwQPNDCgUI1wv0wlfe+01c/nllydiduGGCGpIaIwIn2DKCc8WE/CUU04RIc1AxWB71FFHieBGWCCQcoF2SMrXjiFrmeJywIrIJjSD0BYYXHEpcG60F4Q5mhYDOAL24YcfFtcJUec4EIwlCIRQcho5x7/mmmvkXHE9IbDdYM/zwiwnz3afffaRdWGgPbs0K6cp8qzbtGkj1zV69OjKfsF5XH311XIeHK+8vFwGNYLG9CfcLaxzcI+CKVwI4EyXBc82itCMjT3xyOC0xfmOg5iFmTt9+/b1v10aZgPheGWWENva0dbbe++9venTp/tbLE3mvvkf521wXS6ncFLgjB40aJAEMnr06OHZhyqOe5z7BL7cuUycOFGuhXvAZys8K+8F58kMBAIRw4YNk2BRs2bNZGZCLqxQEOd3GOd2mhk7dqzXvn17z2od/pp40Da4v+4+8xkI/vFMrACVmVRWUHhW6Ml3wKwy1/6Cy8CBA5cKOgDPyWpIErhiG9odwZzqIKhEwMgFCoMQ6CQgQwDGCnJvwIABEgiifdAmgsEcAiTMkrOarr+marj+6oJH3PuysjKvRYsWEsAhuOlm3xHkHDNmjPRH2jjH5R6655V5vwnw0pbpw6wrLS2Vts9+rOntWc3Ws4JYZk852JdVEDxrgssMMc6F40+aNKly3/Qx5MTw4cPls7vvbAMETQnCEkjj3lkBLOsddiAMJRNcICgzYBcVradZDYyQaDeM/FFHMlIz8E3hEGd0xCQhOFCdicoojMaM/42RPzOxOik4Dn4mfElVgRnH/G9Sa6KYbLguSKvBnLKdw19bWNAoM++xm1eP39cKB1nHNjwTNC2qMqGRxYVuhLsHE5zZQplwTExvKxCkHVXVrjA9CYxYgSWabi64t2HnnvOs8fFyfpmBHHduuDKqO2YuOAaapnM7BMl1/DCgwfP7zP5D0Iq0JQJc1d0H7i11LnAFYDUGNdgoFJ1Ps6bBzMDHGVf1pyHRYKoTmEDDRdDQqeJWZMkFAYd77rlHIqOYR+TTsY68SnLlEALk0OGjQoCHBXMPgYkZWFMCE7LdY3xrmPPB86DTEqDC55lPwCMbHBPhjKmNAMqEYwZNyKraFaYqLgHcBy6fMQloUxw/m8By5xZHYAK/zyYwIdfxw8B9ytZ/rKYt+bZRpq4yOOQrMEGFZgFgtCUZnigtwQReVM885Sgk4f+rjpdfflmS9AmKoLHQMBEyaJbMgkHQ8ApeRmZr3vq/yg1+Z3yJ+A7ZZ76QLoQ2GBemQDJrh0AQ/juuj78kkzNjLYrvrjrQxtu2bSspSvlCZ+YeknrjNGMlO/hH8Zcy2IcRgighaKxxLTcVmgWA0ZQcPLQ4pn+R78YoGQU6NE7vXKZzHGhwCPSgacq0OTcrIziiY0KGEZrsE5OXnDs3vTAfMO2ZWeXyGOPA4EOg7rbbbpNrQxCTK3jttdfKbJXMoEIcuGdcO3mZXEM+EKwiIMI5k5akZAf3BkFGBvWwwToEJm6U2PcVn6aSPtxMDIJPhcCa0JWOdocLXAWDCzjdmdERnDWSDQIqBAF49YWbRRUVq6F748aN8+rVqyclv4oVriPOjJOwLFiwYJlA1spCPveY9k2fmjBhgr8mP1TTTClodmhBmTl2ScFoGyxuzChM8Qr8fEH/H2bPYYcdllMjI5BAQAmi5mLiUyRFiNxJNMuysjLx5x144IH+FsUHlkasF3eFBN9cTbhx0kg+95jUJH4Td4KFRs9TCqYzggM/WZxIX1jwuR500EGSzI0pG1bw0XxuuukmyZ9NigMOOEAqEiVpOisrNygFBOrIryYXNE5FNRWaKcU9ZKLnTD3LdypfWJiHTEFX0qTcnOMwoAkTTCIdJCmYy48AV5SkSFQJQWgq6YREXqrEkLxdaEh8zvRnKsqKAu2a9h0mCb461KeZYqjj6KYAFhK0WqYhZvozFWVFgfxXIu5JpHGp0EwxFFygkAOmcyEhd5GKPuRVRk2NUpS0Y5VD6UP0pWCJu3xRoZlimEFBwYUpU6ZU1vFMCiLeJHxT7YngD6/ooFAEgpqKREn6KBVlecIMLfJmKSASJwDk0EBQymFmEa9nYJZJEnOkCw0l1Sipx4yiMGAyEdEkURn3AMnhipIkaJnUck2qD6mmmXJ4yEwFdJWv0wzjL+XxouSWMi+chZlP1ZVrU5So0CbHjx8vNRSoaZoEKjRTDlMYGSWpw0naRFohmER1dIQfRV75HAaq1pAGojmZSiHAiqE+J30oqTamQrMI4B075JXxKtW0QpEJ8knxH9FQifpTyBeTKNvC6E8BBUUpJFhozAByleGTQH2aRQIFLJh5g2AiQJRGCCTNmjUrr9lBvPQNN0Scl+4pShAmhlDQg9cPMxU4KVTTLBLQNktKSqRkWhph7KUOZ2lpqb9GUZYvvAWT7JCkZ5eppllEUAiYWpVU9ebVp2mClCjel0TJNZLxEfDkf1JZOxsUmuBdNPg0QTVNJUlmzpxp+vTpI1kZSU/YUKFZZGCe4w/kfeJpqnBDLc3u3btLgjwvGevSpUuooh/4P5m7jrOexHoqL9HYq6oArijVwas1unbtKvnGSZrlDhWaRQaPy5Vh6927d6QybIWGnEsWSpYpyvKA/sEgzBsyyfktRP9QoVmEMJuHBHK0sTQJTUVZ3tRE31ChqSiKEgGNniuKokRAhaaiKEoEVGgqiqJEQIWmoihKBFRoKoqiRECFpqIoSgRUaCqKokRAhaaiKEpojPkfSMv3tOIAqdMAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "c6f404a3",
   "metadata": {},
   "source": [
    "### PPL (Perplexity)\n",
    " - 모델이 얼마나 헷갈려하는지를 나타내는 지표\n",
    " - PPL 이 낮을 수록, 다음 단어를 헷갈려하지 않고 잘 예측하는 모델이라고 생각할 수 있다.\n",
    " - 모델이 문장을 예측할 때 평균적으로 몇 개의 선택지 앞에서 고민하고 있는지를 수치로 표현한 것이라고 볼 수 있다.\n",
    " - ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48f94a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chech\\Desktop\\machine_learning_study\\machine_learning_venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] .gitattributes\n",
      "[OK] README.md\n",
      "[OK] kowikitext_20240301.dev\n",
      "[OK] kowikitext_20240301.test\n",
      "[OK] kowikitext_20240301.train.zip\n",
      "\n",
      "총 다운로드 파일 수: 5\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "import os\n",
    "\n",
    "repo_id = \"teneriffa/kowikitext-20240301\"\n",
    "api = HfApi()\n",
    "\n",
    "files = api.list_repo_files(repo_id, repo_type=\"dataset\")\n",
    "len(files), files[:20]\n",
    "\n",
    "save_dir = \"../kowikitext_dataset\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "downloaded = []\n",
    "\n",
    "for fname in files:\n",
    "    try:\n",
    "        path = hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"dataset\",\n",
    "            filename=fname,\n",
    "            local_dir=save_dir,\n",
    "            local_dir_use_symlinks=False, \n",
    "        )\n",
    "        downloaded.append(path)\n",
    "        print(f\"[OK] {fname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] {fname} -> {e}\")\n",
    "\n",
    "print(f\"\\n총 다운로드 파일 수: {len(downloaded)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70d8b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 해제 완료 & zip 삭제\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = os.path.join(save_dir, \"kowikitext_20240301.train.zip\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(save_dir)\n",
    "\n",
    "os.remove(zip_path)\n",
    "\n",
    "print(\"압축 해제 완료 & zip 삭제\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f9f9c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15068050, 76378, 74630)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_spaces(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def load_and_clean_txt(path):\n",
    "    cleaned = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = normalize_spaces(line)\n",
    "            if not line:\n",
    "                continue\n",
    "            cleaned.append(line)\n",
    "    return cleaned\n",
    "\n",
    "train_texts = load_and_clean_txt(\"../kowikitext_dataset/kowikitext_20240301.train\")\n",
    "valid_texts = load_and_clean_txt(\"../kowikitext_dataset/kowikitext_20240301.dev\")\n",
    "test_texts  = load_and_clean_txt(\"../kowikitext_dataset/kowikitext_20240301.test\")\n",
    "\n",
    "len(train_texts), len(valid_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afe84c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500001,\n",
       " ['=',\n",
       "  '틀:원소',\n",
       "  '정보/헬륨',\n",
       "  '=',\n",
       "  '=',\n",
       "  '분류:세기별',\n",
       "  '탄자니아',\n",
       "  '사람',\n",
       "  '=',\n",
       "  '=',\n",
       "  'Eva',\n",
       "  '(나이트위시의',\n",
       "  '노래)',\n",
       "  '=',\n",
       "  'Eva는',\n",
       "  '2007년',\n",
       "  '5월',\n",
       "  '25일에',\n",
       "  '발매된',\n",
       "  '나이트위시의'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공백으로 토큰화\n",
    "def whitespace_tokenize(text):\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split(\" \") if text else []\n",
    "\n",
    "def build_tokens(texts, max_lines=100_000, max_tokens=500_000):\n",
    "    tokens = []\n",
    "    for line in texts[:max_lines]:\n",
    "        tokens.extend(whitespace_tokenize(line))\n",
    "        if len(tokens) >= max_tokens:\n",
    "            break\n",
    "    return tokens\n",
    "\n",
    "train_tokens = build_tokens(train_texts)\n",
    "len(train_tokens), train_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7da166b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class NGramLM:\n",
    "    def __init__(self, n, alpha=1.0):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.ngram = Counter()\n",
    "        self.context = Counter()\n",
    "        self.vocab = set()\n",
    "\n",
    "    def fit(self, tokens):\n",
    "        self.vocab = set(tokens)\n",
    "        pad = [\"<s>\"] * (self.n - 1)\n",
    "        tokens = pad + tokens + [\"</s>\"]\n",
    "\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            g = tuple(tokens[i:i+self.n])\n",
    "            c = g[:-1]\n",
    "            self.ngram[g] += 1\n",
    "            self.context[c] += 1\n",
    "\n",
    "    def prob(self, ngram):\n",
    "        c = ngram[:-1]\n",
    "        V = max(len(self.vocab), 1)\n",
    "        return (self.ngram[ngram] + self.alpha) / (self.context[c] + self.alpha * V)\n",
    "\n",
    "    def sent_logprob(self, tokens):\n",
    "        pad = [\"<s>\"] * (self.n - 1)\n",
    "        tokens = pad + tokens + [\"</s>\"]\n",
    "\n",
    "        logp, N = 0.0, 0\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            g = tuple(tokens[i:i+self.n])\n",
    "            logp += math.log(self.prob(g))\n",
    "            N += 1\n",
    "        return logp, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44a7095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, texts, max_lines=20_000):\n",
    "    total_logp, total_N = 0.0, 0\n",
    "\n",
    "    for line in texts[:max_lines]:\n",
    "        tokens = whitespace_tokenize(line)\n",
    "        if not tokens:\n",
    "            continue\n",
    "        logp, N = model.sent_logprob(tokens)\n",
    "        total_logp += logp\n",
    "        total_N += N\n",
    "\n",
    "    return math.exp(-total_logp / total_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c119d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram PPL: 51188.54\n",
      "2-gram PPL: 96787.73\n",
      "3-gram PPL: 138439.01\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 2, 3]:\n",
    "    lm = NGramLM(n)\n",
    "    lm.fit(train_tokens)\n",
    "\n",
    "    ppl = perplexity(lm, valid_texts)\n",
    "    print(f\"{n}-gram PPL: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cfa22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_ngram_model(model, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"n\": model.n,\n",
    "            \"alpha\": model.alpha,\n",
    "            \"ngram\": model.ngram,\n",
    "            \"context\": model.context,\n",
    "            \"vocab\": model.vocab,\n",
    "        }, f)\n",
    "\n",
    "def load_ngram_model(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    model = NGramLM(data[\"n\"], data[\"alpha\"])\n",
    "    model.ngram = data[\"ngram\"]\n",
    "    model.context = data[\"context\"]\n",
    "    model.vocab = data[\"vocab\"]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42204d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NGramLM(n=2)   # bigram\n",
    "lm.fit(train_tokens)\n",
    "\n",
    "save_ngram_model(lm, \"./models/bigram_ngram.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aeb5a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_top_ngrams(model, top_k=1000, path=\"top_ngrams.json\"):\n",
    "    items = model.ngram.most_common(top_k)\n",
    "    readable = {\n",
    "        \" \".join(k): v for k, v in items\n",
    "    }\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(readable, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "save_top_ngrams(lm, top_k=50, path=\"./models/bigram_top50.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
